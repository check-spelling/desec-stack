user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log info;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format main '$host:$server_port $remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" $ssl_protocol/$ssl_cipher';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    # don't show version number in error pages etc.
    server_tokens off;

    ### set up rate limits
    # set up one bucket per remote ip for (costly) API access
    limit_req_zone $binary_remote_addr zone=perip-api:100m rate=30r/s;
    # set up one bucket per remote ip for checkip service (we've observed excessive use with 730,000 requests/day)
    limit_req_zone $binary_remote_addr zone=perip-checkip:100m rate=3r/m;

    # If limit_req directives are defined here, they apply to all servers that don't have their own ones
    #
    # NOTE that nginx' 'return' occurs before rate limiting and all sections using 'return' are thus
    # not affected by any rate limiting. (This is okay, simply executing the return is cheaper than doing
    # the rate limit computation.) Further rate limits need to be implemented using a firewall.
    #
    # specific limits will be defined in the appropriate sections of the configuration

    limit_req_status 429;
    error_page 429 /429.html;

    ### configure API upstream
    upstream desecapi {
        # we allow as many connections as the api has worker threads.
        # see https://github.com/desec-io/desec-stack/blob/4c6e9a7beea9446b039d64bd05608a2a8b67dbda/api/uwsgi.ini#L5-L6
        server api:3031 max_conns=64;
    }


    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}
